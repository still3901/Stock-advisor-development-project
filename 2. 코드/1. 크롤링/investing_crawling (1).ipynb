{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install selenium\n",
    "#!pip install webdriver-manager\n",
    "#!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_news_urls = [\n",
    "    \n",
    "    \"https://www.investing.com/equities/advanced-semiconductor-engineering-news\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜 형식 정의\n",
    "date_format = \"%b %d, %Y\"\n",
    "\n",
    "# 기사 데이터 저장 리스트\n",
    "articles = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주식 뉴스 URL 리스트\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "for url in stock_news_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # 페이지 로드 대기\n",
    "\n",
    "# 기사 데이터 저장 리스트\n",
    "articles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_articles(driver):\n",
    "    for i in range(1, 11):  # 1부터 10까지 반복\n",
    "        try:\n",
    "            # 기사 영역 XPath\n",
    "            article_xpath = f\"//ul/li[{i}]/article\"\n",
    "            print(f\"Trying to find article element with XPath: {article_xpath}\")\n",
    "            article_element = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, article_xpath))\n",
    "            )\n",
    "\n",
    "            # 헤드라인 XPath\n",
    "            headline_xpath = f\"{article_xpath}/div/a\"\n",
    "            print(f\"Trying to find headline with XPath: {headline_xpath}\")\n",
    "            headline = driver.find_element(By.XPATH, headline_xpath).text\n",
    "\n",
    "            # 게시 날짜 XPath\n",
    "            date_xpath = f\"{article_xpath}/div/ul/li[2]/time\"\n",
    "            print(f\"Trying to find date with XPath: {date_xpath}\")\n",
    "            date_str = driver.find_element(By.XPATH, date_xpath).text\n",
    "\n",
    "            # 날짜 형식 처리\n",
    "            try:\n",
    "                date_obj = datetime.strptime(date_str, date_format)\n",
    "            except Exception:\n",
    "                print(f\"Unable to parse date: {date_str}. Using today's date instead.\")\n",
    "                date_obj = datetime.now()  # 날짜 형식이 맞지 않으면 오늘 날짜로 처리\n",
    "\n",
    "            # 기사 데이터 저장\n",
    "            articles.append({\n",
    "                \"headline\": headline,\n",
    "                \"date\": date_obj,\n",
    "                \"comments\": []\n",
    "            })\n",
    "\n",
    "            # 댓글 클릭 XPath\n",
    "            comment_icon_xpath = f\"{article_xpath}/div/ul/li[3]/a\"\n",
    "            print(f\"Trying to find comment icon with XPath: {comment_icon_xpath}\")\n",
    "            if driver.find_elements(By.XPATH, comment_icon_xpath):\n",
    "                article_url = driver.current_url\n",
    "                driver.find_element(By.XPATH, comment_icon_xpath).click()\n",
    "                time.sleep(2)  # 페이지 로드 대기\n",
    "\n",
    "                # 댓글 수집\n",
    "                collect_comments(driver, i)\n",
    "\n",
    "                # 원래 기사 페이지로 돌아가기\n",
    "                driver.get(article_url)\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, article_xpath))\n",
    "                )\n",
    "                time.sleep(2)  # 페이지 로드 대기\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(f\"TimeoutException: Unable to locate element for article {i} with XPath: {article_xpath}\")\n",
    "        except NoSuchElementException:\n",
    "            print(f\"NoSuchElementException: Unable to locate element for article {i} with XPath: {article_xpath}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error collecting article {i}: {e}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to find article element with XPath: //ul/li[1]/article\n",
      "Trying to find headline with XPath: //ul/li[1]/article/div/a\n",
      "Trying to find date with XPath: //ul/li[1]/article/div/ul/li[2]/time\n",
      "Trying to find comment icon with XPath: //ul/li[1]/article/div/ul/li[3]/a\n",
      "Trying to find article element with XPath: //ul/li[2]/article\n",
      "Trying to find headline with XPath: //ul/li[2]/article/div/a\n",
      "Trying to find date with XPath: //ul/li[2]/article/div/ul/li[2]/time\n",
      "Trying to find comment icon with XPath: //ul/li[2]/article/div/ul/li[3]/a\n",
      "Trying to find article element with XPath: //ul/li[3]/article\n",
      "Trying to find headline with XPath: //ul/li[3]/article/div/a\n",
      "Trying to find date with XPath: //ul/li[3]/article/div/ul/li[2]/time\n",
      "Trying to find comment icon with XPath: //ul/li[3]/article/div/ul/li[3]/a\n",
      "Trying to find article element with XPath: //ul/li[4]/article\n",
      "Trying to find headline with XPath: //ul/li[4]/article/div/a\n",
      "Trying to find date with XPath: //ul/li[4]/article/div/ul/li[2]/time\n",
      "Trying to find comment icon with XPath: //ul/li[4]/article/div/ul/li[3]/a\n",
      "Trying to find article element with XPath: //ul/li[5]/article\n",
      "Trying to find headline with XPath: //ul/li[5]/article/div/a\n",
      "Trying to find date with XPath: //ul/li[5]/article/div/ul/li[2]/time\n",
      "Trying to find comment icon with XPath: //ul/li[5]/article/div/ul/li[3]/a\n",
      "Trying to find article element with XPath: //ul/li[6]/article\n",
      "Trying to find headline with XPath: //ul/li[6]/article/div/a\n",
      "Trying to find date with XPath: //ul/li[6]/article/div/ul/li[2]/time\n",
      "Trying to find comment icon with XPath: //ul/li[6]/article/div/ul/li[3]/a\n",
      "Trying to find article element with XPath: //ul/li[7]/article\n",
      "Trying to find headline with XPath: //ul/li[7]/article/div/a\n",
      "Trying to find date with XPath: //ul/li[7]/article/div/ul/li[2]/time\n",
      "Trying to find comment icon with XPath: //ul/li[7]/article/div/ul/li[3]/a\n",
      "Trying to find article element with XPath: //ul/li[8]/article\n",
      "Trying to find headline with XPath: //ul/li[8]/article/div/a\n",
      "Trying to find date with XPath: //ul/li[8]/article/div/ul/li[2]/time\n",
      "Unable to parse date: 29 minutes ago. Using today's date instead.\n",
      "Trying to find comment icon with XPath: //ul/li[8]/article/div/ul/li[3]/a\n",
      "Trying to find article element with XPath: //ul/li[9]/article\n",
      "Trying to find headline with XPath: //ul/li[9]/article/div/a\n",
      "Trying to find date with XPath: //ul/li[9]/article/div/ul/li[2]/time\n",
      "Trying to find comment icon with XPath: //ul/li[9]/article/div/ul/li[3]/a\n",
      "Trying to find article element with XPath: //ul/li[10]/article\n",
      "Trying to find headline with XPath: //ul/li[10]/article/div/a\n",
      "Trying to find date with XPath: //ul/li[10]/article/div/ul/li[2]/time\n",
      "Trying to find comment icon with XPath: //ul/li[10]/article/div/ul/li[3]/a\n",
      "{'headline': 'Earnings call: ASE Technology reports mixed Q1 results, plans growth', 'date': datetime.datetime(2024, 4, 29, 0, 0), 'comments': []}\n",
      "{'headline': 'ASE Industrial ADR earnings beat by $1.20, revenue topped estimates', 'date': datetime.datetime(2024, 4, 25, 0, 0), 'comments': []}\n",
      "{'headline': 'Aussie bourse operator ASX falls on earnings miss; plans job cuts', 'date': datetime.datetime(2024, 2, 15, 0, 0), 'comments': []}\n",
      "{'headline': 'Earnings call: ASE Technology reports mixed results amid market downturn', 'date': datetime.datetime(2024, 2, 1, 0, 0), 'comments': []}\n",
      "{'headline': 'ASE Industrial ADR earnings beat by $2.01, revenue topped estimates', 'date': datetime.datetime(2024, 2, 1, 0, 0), 'comments': []}\n",
      "{'headline': 'ASE Technology reports dip in Q4 net income, revenue', 'date': datetime.datetime(2024, 2, 1, 0, 0), 'comments': []}\n",
      "{'headline': 'ASE Technology reports dip in December revenues', 'date': datetime.datetime(2024, 1, 9, 0, 0), 'comments': []}\n",
      "{'headline': 'Technology one receives Investment Bank Analyst Rating Update', 'date': datetime.datetime(2024, 5, 24, 14, 13, 22, 970577), 'comments': []}\n",
      "{'headline': \"These stocks will benefit from Nvidia's new AI superchip GB200: Morgan Stanley\", 'date': datetime.datetime(2024, 5, 14, 0, 0), 'comments': []}\n",
      "{'headline': 'Advanced Semiconductor Engineering receives Investment Bank Analyst Rating Update', 'date': datetime.datetime(2024, 4, 26, 0, 0), 'comments': []}\n"
     ]
    }
   ],
   "source": [
    "def collect_comments(driver, article_index):\n",
    "    try:\n",
    "        # 댓글 아이콘 클릭 (이미 클릭한 상태라고 가정)\n",
    "        time.sleep(2)  # 페이지 로드 대기\n",
    "\n",
    "        # 'View all comments' 버튼 클릭\n",
    "        show_all_comments_button_xpath = \"/html/body/div[1]/div[2]/div[2]/div[2]/div[1]/div/div[13]/div/div/div[3]\"\n",
    "        if driver.find_elements(By.XPATH, show_all_comments_button_xpath):\n",
    "            driver.find_element(By.XPATH, show_all_comments_button_xpath).click()\n",
    "            time.sleep(2)  # 댓글 로드 대기\n",
    "\n",
    "        # 댓글 수집\n",
    "        comments = []\n",
    "        i = 1\n",
    "        while True:\n",
    "            comment_xpath = f\"/html/body/div[1]/div[2]/div[2]/div[2]/div[1]/div/div[13]/div/div/div[{i}]/div[1]/div[2]\"\n",
    "            if driver.find_elements(By.XPATH, comment_xpath):\n",
    "                comment = driver.find_element(By.XPATH, comment_xpath).text\n",
    "                comments.append(comment)\n",
    "                i += 1\n",
    "            else:\n",
    "                break  # 댓글이 더 이상 없으면 루프 종료\n",
    "\n",
    "        # 기사 데이터에 댓글 추가\n",
    "        articles[article_index - 1][\"comments\"] = comments\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error collecting comments for article {article_index}: {e}\")\n",
    "\n",
    "# 기사 수집 반복문\n",
    "# 엔비디아 30전까지 = df_NVDI1 / 30부터 79까지 df_NVDI2 / 80부터 끝까지 df_NVDI3\n",
    "page = 1\n",
    "while True:\n",
    "    collect_articles(driver)\n",
    "    # 다음 페이지 버튼 클릭\n",
    "    next_button_xpath = \"/html/body/div[1]/div[2]/div[2]/div[2]/div[1]/div[3]/a[2]\"\n",
    "    if driver.find_elements(By.XPATH, next_button_xpath):\n",
    "        driver.find_element(By.XPATH, next_button_xpath).click()\n",
    "        time.sleep(5)  # 페이지 로드 대기\n",
    "        page += 1\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "    \n",
    "    if not articles:\n",
    "        break\n",
    "\n",
    "    # 수집한 마지막 기사의 날짜가 1년 이상 지난 경우 중지\n",
    "    if (datetime.now() - articles[-1][\"date\"]).days > 365:\n",
    "        break\n",
    "\n",
    "# 드라이버 종료\n",
    "driver.quit()\n",
    "\n",
    "# 수집한 기사 데이터 출력\n",
    "for article in articles:\n",
    "    print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            headline  \\\n",
      "1  ASE Industrial ADR earnings beat by $1.20, rev...   \n",
      "4  ASE Industrial ADR earnings beat by $2.01, rev...   \n",
      "6    ASE Technology reports dip in December revenues   \n",
      "5  ASE Technology reports dip in Q4 net income, r...   \n",
      "9  Advanced Semiconductor Engineering receives In...   \n",
      "2  Aussie bourse operator ASX falls on earnings m...   \n",
      "0  Earnings call: ASE Technology reports mixed Q1...   \n",
      "3  Earnings call: ASE Technology reports mixed re...   \n",
      "7  Technology one receives Investment Bank Analys...   \n",
      "8  These stocks will benefit from Nvidia's new AI...   \n",
      "\n",
      "                        date comments  \n",
      "1 2024-04-25 00:00:00.000000           \n",
      "4 2024-02-01 00:00:00.000000           \n",
      "6 2024-01-09 00:00:00.000000           \n",
      "5 2024-02-01 00:00:00.000000           \n",
      "9 2024-04-26 00:00:00.000000           \n",
      "2 2024-02-15 00:00:00.000000           \n",
      "0 2024-04-29 00:00:00.000000           \n",
      "3 2024-02-01 00:00:00.000000           \n",
      "7 2024-05-24 14:13:22.970577           \n",
      "8 2024-05-14 00:00:00.000000           \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 기사 데이터를 데이터프레임으로 변환\n",
    "df = pd.DataFrame(articles, columns=[\"headline\", \"date\", \"comments\"])\n",
    "\n",
    "# 댓글을 문자열로 변환 (리스트를 문자열로 변환하여 저장)\n",
    "df['comments'] = df['comments'].apply(lambda x: ' | '.join(x) if x else '')\n",
    "df = df.sort_values(by='headline')\n",
    "\n",
    "# 데이터프레임 저장 (CSV 파일)\n",
    "df.to_csv('df_NVDA3.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 데이터프레임 출력\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10 entries, 1 to 8\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   headline  10 non-null     object        \n",
      " 1   date      10 non-null     datetime64[ns]\n",
      " 2   comments  10 non-null     object        \n",
      "dtypes: datetime64[ns](1), object(2)\n",
      "memory usage: 320.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    \n",
       "4    \n",
       "6    \n",
       "5    \n",
       "9    \n",
       "2    \n",
       "0    \n",
       "3    \n",
       "7    \n",
       "8    \n",
       "Name: comments, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
